"""
Interface Streamlit para o Sistema de Agentes BancÃ¡rios
"""
import streamlit as st
import os
from dotenv import load_dotenv
from orchestrator import Orchestrator

# Carrega variÃ¡veis de ambiente
load_dotenv()

# ConfiguraÃ§Ã£o da pÃ¡gina
st.set_page_config(
    page_title="Banco Ãgil - Atendimento Virtual",
    page_icon="ğŸ¦",
    layout="wide"
)

# Inicializa o orquestrador na sessÃ£o
if "orchestrator" not in st.session_state:
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        st.error("âš ï¸ GOOGLE_API_KEY nÃ£o encontrada! Configure no arquivo .env")
        st.stop()
    st.session_state.orchestrator = Orchestrator(api_key=api_key)
    st.session_state.mensagens = []
    st.session_state.encerrado = False
    st.session_state.chain_of_thought = False  # CoT desativado por padrÃ£o

# TÃ­tulo e descriÃ§Ã£o
st.title("ğŸ¦ Banco Ãgil - Atendimento Virtual")
st.markdown("---")
st.markdown("""
Bem-vindo ao nosso sistema de atendimento inteligente! 
Nossos agentes especializados estÃ£o prontos para ajudÃ¡-lo com:
- ğŸ” AutenticaÃ§Ã£o e triagem
- ğŸ’³ Consultas e solicitaÃ§Ãµes de crÃ©dito
- ğŸ“Š Entrevista de crÃ©dito para atualizaÃ§Ã£o de score
- ğŸ’± Consulta de cotaÃ§Ãµes de moedas
""")

# Sidebar com informaÃ§Ãµes
with st.sidebar:
    st.header("â„¹ï¸ InformaÃ§Ãµes")
    st.markdown("""
    ### Agente Atual
    **{}**
    """.format(st.session_state.orchestrator._obter_nome_agente_atual()))
    
    if st.session_state.orchestrator.contexto.get("autenticado"):
        cliente = st.session_state.orchestrator.contexto.get("cliente")
        if cliente:
            st.markdown("### ğŸ‘¤ Cliente Autenticado")
            st.write(f"**Nome:** {cliente.get('nome', 'N/A')}")
            st.write(f"**CPF:** {cliente.get('cpf', 'N/A')}")
            st.write(f"**Limite Atual:** R$ {float(cliente.get('limite_credito', 0)):,.2f}")
            
            # Mostra score e limite mÃ¡ximo se disponÃ­vel (apÃ³s entrevista)
            if "ultimo_resultado" in st.session_state:
                resultado = st.session_state.ultimo_resultado
                if resultado and isinstance(resultado, dict) and resultado.get("score_calculado"):
                    st.markdown("---")
                    st.markdown("### ğŸ“Š Resultado da Entrevista")
                    st.success(f"**Score:** {resultado['score_calculado']} pontos")
                    if resultado.get("limite_maximo"):
                        st.info(f"**Limite MÃ¡ximo:** R$ {resultado['limite_maximo']:,.2f}")
    
    st.markdown("---")
    
    # Toggle de Chain-of-Thought
    st.header("âš™ï¸ ConfiguraÃ§Ãµes")
    cot_enabled = st.toggle(
        "ğŸ’­ Chain-of-Thought",
        value=st.session_state.get("chain_of_thought", False),
        help="Quando ativado, o agente explica seu raciocÃ­nio antes de responder"
    )
    if cot_enabled != st.session_state.get("chain_of_thought", False):
        st.session_state.chain_of_thought = cot_enabled
        st.rerun()
    
    st.markdown("---")
    
    # SeÃ§Ã£o de Debug da IA
    st.header("ğŸ” Debug da IA")
    
    # Inicializa debug_info e Ã­ndice na sessÃ£o
    if "debug_info" not in st.session_state:
        st.session_state.debug_info = []
    if "debug_idx" not in st.session_state:
        st.session_state.debug_idx = 0
    if "ultimo_resultado" not in st.session_state:
        st.session_state.ultimo_resultado = {}
    
    if st.session_state.debug_info:
        total = len(st.session_state.debug_info)
        
        # NavegaÃ§Ã£o
        col1, col2, col3 = st.columns([1, 2, 1])
        
        with col1:
            if st.button("â—€ Anterior", disabled=st.session_state.debug_idx <= 0):
                st.session_state.debug_idx -= 1
                st.rerun()
        
        with col2:
            # Atualiza Ã­ndice para o Ãºltimo se necessÃ¡rio
            if st.session_state.debug_idx >= total:
                st.session_state.debug_idx = total - 1
            st.markdown(f"**Chamada {st.session_state.debug_idx + 1} de {total}**")
        
        with col3:
            if st.button("PrÃ³xima â–¶", disabled=st.session_state.debug_idx >= total - 1):
                st.session_state.debug_idx += 1
                st.rerun()
        
        # BotÃ£o para ir direto ao Ãºltimo
        if st.button("â­ï¸ Ir para Ãºltima chamada"):
            st.session_state.debug_idx = total - 1
            st.rerun()
        
        # Mostra chamada selecionada
        debug = st.session_state.debug_info[st.session_state.debug_idx]
        
        # Info compacta
        modelo = debug.get("modelo_usado", "N/A")
        tempo = debug.get("tempo_ms", 0)
        st.caption(f"ğŸ¤– `{modelo}` | â±ï¸ {tempo}ms")
        
        if debug.get("contexto"):
            st.caption(f"ğŸ“ {debug['contexto']}")
        
        # RaciocÃ­nio (Chain-of-Thought) - mostra primeiro se houver
        if debug.get("raciocinio"):
            with st.expander("ğŸ’­ RaciocÃ­nio (Chain-of-Thought)", expanded=True):
                st.info(debug.get("raciocinio", ""))
        
        # Tool calls - usa tool_calls_completos se disponÃ­vel (tem mais detalhes)
        tool_calls = debug.get("tool_calls_completos", debug.get("tool_calls", []))
        if tool_calls:
            # Suporta tanto formato antigo (lista de strings) quanto novo (lista de dicts)
            if isinstance(tool_calls[0], dict):
                # Filtra responder_usuario (jÃ¡ mostrou o raciocÃ­nio acima)
                other_tools = [tc for tc in tool_calls if tc.get("name") != "responder_usuario"]
                
                if other_tools:
                    tool_names = [tc.get("name", "unknown") for tc in other_tools]
                    st.success(f"ğŸ”§ Tools: {', '.join(tool_names)}")
                    
                    with st.expander("ğŸ”§ Ver detalhes das Tool Calls", expanded=False):
                        for tc in other_tools:
                            st.markdown(f"**{tc.get('name', 'unknown')}**")
                            st.code(f"Args: {tc.get('args', {})}", language="python")
                            if tc.get("result"):
                                st.code(f"Result: {tc.get('result', {})}", language="python")
                            st.markdown("---")
            else:
                st.success(f"ğŸ”§ Tools: {', '.join(tool_calls)}")
        
        # System prompt, prompt do usuÃ¡rio e resposta em expanders
        if debug.get("system_prompt"):
            with st.expander("ğŸ§  Ver System Prompt", expanded=False):
                st.code(debug.get("system_prompt", "N/A"), language="text")
        
        with st.expander("ğŸ“¤ Ver Mensagem do UsuÃ¡rio", expanded=False):
            st.code(debug.get("prompt", "N/A"), language="text")
        
        if debug.get("erro"):
            st.error(f"âŒ {debug['erro']}")
        else:
            with st.expander("ğŸ“¥ Ver Resposta", expanded=True):
                st.code(debug.get("resposta", "N/A"), language="text")
    else:
        st.info("â„¹ï¸ Nenhuma chamada Ã  IA ainda.")
    
    st.markdown("---")
    
    if st.button("ğŸ”„ Reiniciar Conversa"):
        st.session_state.orchestrator.resetar()
        st.session_state.mensagens = []
        st.session_state.encerrado = False
        st.session_state.debug_info = []
        st.session_state.debug_idx = 0
        st.session_state.ultimo_resultado = {}
        st.rerun()
    
    st.markdown("---")
    st.markdown("### ğŸ“ Dados de Teste")
    st.markdown("""
    **CPF:** 12345678900  
    **Data Nascimento:** 15/05/1990
    
    **CPF:** 98765432100  
    **Data Nascimento:** 22/08/1985
    """)

# Ãrea de mensagens
st.header("ğŸ’¬ Conversa")

# Exibe histÃ³rico de mensagens
for idx, msg in enumerate(st.session_state.mensagens):
    if msg["tipo"] == "usuario":
        with st.chat_message("user"):
            st.write(msg["conteudo"])
    else:
        with st.chat_message("assistant"):
            st.write(msg["conteudo"])
            if msg.get("agente"):
                st.caption(f"Agente: {msg['agente']}")

# Se a conversa foi encerrada, mostra mensagem
if st.session_state.encerrado:
    st.info("ğŸ’¬ A conversa foi encerrada. Clique em 'Reiniciar Conversa' para comeÃ§ar uma nova.")
else:
    # Input do usuÃ¡rio
    mensagem_usuario = st.chat_input("Digite sua mensagem aqui...")
    
    if mensagem_usuario:
        # Adiciona mensagem do usuÃ¡rio
        st.session_state.mensagens.append({
            "tipo": "usuario",
            "conteudo": mensagem_usuario
        })
        
        # Processa mensagem (passa config de Chain-of-Thought)
        with st.spinner("Processando..."):
            cot_config = {"chain_of_thought": st.session_state.get("chain_of_thought", False)}
            resultado = st.session_state.orchestrator.processar_mensagem(mensagem_usuario, config=cot_config)
        
        # Armazena informaÃ§Ãµes de debug (acumula se jÃ¡ existir)
        if resultado.get("debug_info"):
            # Se jÃ¡ existe debug_info, adiciona ao final (acumula histÃ³rico)
            if st.session_state.debug_info:
                st.session_state.debug_info.extend(resultado["debug_info"])
            else:
                st.session_state.debug_info = resultado["debug_info"]
            # Move Ã­ndice para a Ãºltima chamada
            st.session_state.debug_idx = len(st.session_state.debug_info) - 1
        
        # Salva resultado para mostrar score/limite no sidebar
        st.session_state.ultimo_resultado = resultado
        
        # Se houve erro, mostra alerta
        if resultado.get("erro"):
            st.error(f"âš ï¸ Erro na interpretaÃ§Ã£o da IA: {resultado['erro']}")
        
        # Adiciona resposta do agente
        st.session_state.mensagens.append({
            "tipo": "agente",
            "conteudo": resultado["resposta"],
            "agente": resultado["agente_atual"]
        })
        
        # Verifica se deve encerrar
        if resultado.get("encerrar"):
            st.session_state.encerrado = True
        
        st.rerun()

# RodapÃ©
st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    <small>Banco Ãgil - Sistema de Agentes Inteligentes | Desenvolvido para Tech4Humans</small>
</div>
""", unsafe_allow_html=True)

